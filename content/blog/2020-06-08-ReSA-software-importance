---
title: "Evidence for the importance of research software"
date: 2020-06-08
author: "Michelle Barker, Daniel S. Katz, Alejandra Gonzalez-Beltran"
---


(This post is cross-posted on the [SSI blog](https://www.software.ac.uk/blog) and the [Netherlands eScience Center blog](https://blog.esciencecenter.nl), and is archived as [https://doi.org/10.5281/zenodo.xxxxx](https://doi.org/10.5281/zenodo.3873832))

This blog analyses work evidencing the importance of research software to research outcomes, to enable the research software community to find useful evidence to share with key influencers. This analysis considers papers relating to meta-research, policy, community, education and training, research breakthroughs and specific software.

The [Research Software Alliance](http://www.researchsoft.org/) (ReSA) [Taskforce for the importance of research software](http://www.researchsoft.org/resa-taskforces-join-us/) was formed initially to bring together existing evidence showing the importance of research software in the research process. This kind of information is critical to achieving ReSA’s vision to have research software recognised and valued as a fundamental and vital component of research worldwide.

**Methodology**

The Taskforce has utilised crowdsourcing to locate resources in line with ReSA’s mission to bring research software communities together to collaborate on the advancement of research software. The Taskforce invited [ReSA google group members](https://groups.google.com/forum/?pli=1#!forum/research-software-alliance) in late 2019 to submit evidence about the importance of software in research to a [Zotero group library](https://www.zotero.org/groups/2400609/resa/library). Evidence could be from a wide range of sources including newspapers, blogs, peer-reviewed journals, policy documents and datasets. 

The submissions to Zotero submitted to date highlight the significant role that software plays in research. We decided to tag the submissions based on analysis of the submissions and how [some community research software organisations](http://urssi.us/blog/2020/03/11/the-research-software-alliance-resa-and-the-community-landscape/) categorise focus areas. Some of the documents were also tagged by country and/or research discipline to enable users to search from that perspective were relevant. This resulted in tagging of submissions with one or more of the following tags, which are explained in the following sections:



*   Meta-research 
*   Policy 
*   Community
*   Education and training 
*   Research breakthroughs 
*   Software

**Submission contents**

Explanation of each category, and examples of some of the resources, are highlighted below. It should be noted that some of the resources mentioned below are important in a number of the categories; however, have only been cited here in one category. 

**Meta-research** contains resources that include analysis of how software is developed and used in research: 



*   [Charting the digital transformation of science: Findings from the 2018 OECD International Survey of Scientific Authors (ISSA2)](https://www.oecd-ilibrary.org/science-and-technology/charting-the-digital-transformation-of-science_1b06c47c-en) includes evidence that 25% of research produces new code.
*   [The Ecosystem of Technologies for Social Science Research](https://uk.sagepub.com/en-gb/eur/technologies-for-social-science-research) tracks increase in the use of software tools, along with characteristics of key tools. It is noted that whilst many commercial tools are available, the more innovative ones are coming out of academia.
*   [The top 100 papers](https://www.nature.com/articles/514550a) analyses the top 100 _Nature _papers and finds that the vast majority describe experimental methods or software that have become essential in their fields.
*   [UK Research Software Survey](https://doi.org/10.5281/zenodo.14809) considers responses of 1,000 randomly chosen researchers to show that more than 90% of researchers acknowledged software as being important for their own research, and about 70% of researchers said that their research would not be possible without software.
*   [Understanding Software in Research: Initial Results from Examining Nature and a Call for Collaboration](https://arxiv.org/abs/1706.06527) reveals that “32 of the 40 papers examined mention software, and the 32 papers contain 211 mentions of distinct software, for an average of 6.5 mentions per paper.”    

**Policy** is used to tag resources that focus on policy related to software, including the need for increased policy focus in this area.



*   [An environment for sustainable research software in Germany and beyond: current state, open challenges, and call for action](https://f1000research.com/articles/9-295/v1) examines how German funding bodies are increasingly acknowledging the importance and value of sustainable research software and related infrastructures, and makes recommendations on how to further improve this.
*   [Community Organizations: Changing the Culture in Which Research Software Is Developed and Sustained](https://doi.org/10.1109/MCSE.2018.2883051) found that the US National Science Foundation made 18,592 awards totaling $9.6 billion to projects that[ ](https://arxiv.org/pdf/1811.08473.pdf)mentioned “software” in their abstracts between 1995-2016, which suggests that government funding policy needs to recognise the critical nature of research software.
*   [RDA COVID-19 Working Group Recommendations and Guidelines](https://www.rd-alliance.org/group/rda-covid19-rda-covid19-omics-rda-covid19-epidemiology-rda-covid19-clinical-rda-covid19-0) contains recommendations for policy makers, funders, publishers and research community members working to overcome the challenges of COVID-19.
*   [Recognising the importance of software in research: Research Software Engineers (RSEs), a UK example - Study](https://op.europa.eu/en/publication-detail/-/publication/fd0f6775-e0dd-11e9-9c4e-01aa75ed71a1) is a case study that discusses the current challenges faced by RSEs and policy conclusions to further help support RSEs and to contribute to the progress of open science in Europe.
*   [UK’s research and innovation infrastructure: opportunities to grow our capability](https://www.ukri.org/research/infrastructure/) highlights the importance of software by recognising software and skills as one of the six computational and e-infrastructure themes.

**Community** considers work on the importance of research software communities in ensuring best practice in software development.



*   [Computational Research Software: Challenges and Community Organizations Working for Culture Change](https://sinews.siam.org/Details-Page/computational-research-software-challenges-and-community-organizations-working-for-culture-change) identifies the importance of sustained community in the development of high-quality software, and introduces efforts by grassroots organisations and projects to improve software quality, productivity, and sustainability. These endeavors ensure the integrity of research results and enable more effective collaboration.
*   [Community Organizations: Changing the Culture in Which Research Software Is Developed and Sustained](https://doi.org/10.1109/MCSE.2018.2883051) provides an overview of the grass-roots organisations and projects that have evolved to address growing technical and social challenges in research software productivity, quality, reproducibility, and sustainability. This article then discusses opportunities to leverage their synergistic activities while nurturing work toward emerging software ecosystems.

**Education and training** identifies work that considers issues round skills, training, career paths and reward structures.



*   [How do scientists develop scientific software? An external replication](https://doi.org/10.1109/SANER.2018.8330263) considers how scientists acquire software engineering knowledge to suggest improvements in this process.
*   [Software Use in Astronomy: an Informal Survey](http://arxiv.org/abs/1507.03989) finds that all participants use software in their research, and identifies the ten most popular tools. 90% of participants write at least some of their own software. while only 8% of them report that they have received substantial training in software development.
*   [Unmet needs for analyzing biological big data: A survey of 704 NSF principal investigators](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005755) highlights the importance of skills in software development for data analysis, with 90% of respondents indicating they are currently or will soon be analyzing large data sets.

**Research breakthroughs** include papers on significant research accomplishments that acknowledge reliance on research software tools:



*   [Case Study: First Photograph of a Black Hole, Enabled by NumFOCUS Tools](https://numfocus.org/case-studies/first-photograph-black-hole).
*   [Pegasus powers LIGO gravitational wave de­tection analysis](https://pegasus.isi.edu/2016/02/11/pegasus-powers-ligo-gravitational-waves-detection-analysis/).
*   [Software framework designed to accelerate drug discovery wins IEEE International Scalable Computing Challenge](https://phys.org/news/2018-08-software-framework-drug-discovery-ieee.html).

**Software** has been applied as a tag to resources that mention particular pieces of software, including when this is part of a broader focus in the resource. This category includes a sample of the tens of thousands of papers that rely on research software and that collectively build knowledge in a field, for example:



*   [Analysis of Human Sequence Data Reveals Two Pulses of Archaic Denisovan Admixture](https://doi.org/10.1016/j.cell.2018.02.031).
*   [Challenges in funding and developing genomic software: roots and remedies](https://doi.org/10.1186/s13059-019-1763-7).
*   [Researchers find bug in Python script may have affected hundreds of studies](https://arstechnica.com/information-technology/2019/10/chemists-discover-cross-platform-python-scripts-not-so-cross-platform/).
*   [Securing the future of research computing in the biosciences](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006958).
*   [These 7 CERN Spinoffs Show The Project Isn't Just Theoretical](https://interestingengineering.com/these-7-cern-spinoffs-show-the-project-isnt-just-theoretical).

**Other useful approaches**

This analysis has been useful in elucidating some of the ways in which the value of software can be demonstrated. However, there are also other approaches that could be useful. For example, methods to evaluate economic value are providing valuable statistics for research data, but comparable examples for research software are rare. The recent European Union publication, [Cost-benefit analysis for FAIR research data](https://op.europa.eu/en/publication-detail/-/publication/d375368c-1a0a-11e9-8d04-01aa75ed71a1)<span style="text-decoration:underline;">,</span> finds that the overall cost to the European economy of not having Findable, Accessible, Interoperable and Reusable (FAIR) research data is €10.2bn per year in Europe. A 2014 Australian study by [Houghton and Gruen](https://www.ands.org.au/__data/assets/pdf_file/0019/393022/open-research-data-report.pdf) similarly demonstrates the economic value of data, estimating the value of Australian public research data at over $1.9 billion a year. One of the few economic valuations of research software is a 2017 analysis by [Sweeny et al. ](https://nectar.org.au/wp-content/uploads/2016/06/Estimating-the-value-and-impact-of-Nectar-Virtual-Laboratories-2017.pdf)of the return on investment generated by three Australian virtual laboratories, which provide access to research software and data for researchers, was at least double the investment for every measure. This indicated that the services had a significant economic and user impact - by one measure the value of one virtual laboratory was over 100 times the cost of investment. It would be useful if more studies were undertaken to demonstrate the economic benefits of research software using different methodologies. 

**Conclusion**

This summary of evidence of the importance of research software to research outcomes illustrates increasing recognition of this fact. This summary could also be useful to encourage the community to consider where additional work could be useful (such as expanding existing surveys in specific countries and disciplines to get a more global scope), and to inspire the recording of more of this information (which could include striking examples that convey the impact of failing to understanding the costs and responsibilities of thoughtful software management).

We encourage readers to submit additional resources to the ReSA resources list, which is publicly available:



*   Add it directly to the ReSA [Zotero group library](https://www.zotero.org/groups/2400609/resa/library) (requires Zotero account).
*   Submit an issue in [GitHub](https://github.com/researchsoft/Resources/issues/new/choose) (requires GitHub account).
*   [Email](mailto:info@researchsoft.org) it directly to ReSA.

